{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GenerateOwnData.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMrDa28RTM9C3HXhFra/z9t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"w9HdUkPj2GpH","executionInfo":{"status":"ok","timestamp":1627184357181,"user_tz":-420,"elapsed":5,"user":{"displayName":"Minh Nguyễn Lê","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAYNRGjCirq6Cpw1HL6UX7HEogIFowg0H8D5EI=s64","userId":"13258555114894503374"}}},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import os"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"XhrnFlRz2I2t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627184377778,"user_tz":-420,"elapsed":20601,"user":{"displayName":"Minh Nguyễn Lê","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAYNRGjCirq6Cpw1HL6UX7HEogIFowg0H8D5EI=s64","userId":"13258555114894503374"}},"outputId":"802291fb-e12b-49be-e21f-b913a3d2885c"},"source":["\n","from tensor2tensor.data_generators import problem\n","from tensor2tensor.data_generators import text_encoder\n","from tensor2tensor.data_generators import text_problems\n","from tensor2tensor.data_generators import translate\n","from tensor2tensor.data_generators import wiki_lm\n","from tensor2tensor.utils import registry"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.4 MB 7.1 MB/s \n","\u001b[K     |████████████████████████████████| 649 kB 36.3 MB/s \n","\u001b[K     |████████████████████████████████| 352 kB 54.8 MB/s \n","\u001b[K     |████████████████████████████████| 79 kB 8.5 MB/s \n","\u001b[K     |████████████████████████████████| 679 kB 52.9 MB/s \n","\u001b[K     |████████████████████████████████| 366 kB 54.1 MB/s \n","\u001b[K     |████████████████████████████████| 981 kB 56.8 MB/s \n","\u001b[K     |████████████████████████████████| 5.6 MB 53.0 MB/s \n","\u001b[K     |████████████████████████████████| 191 kB 48.9 MB/s \n","\u001b[K     |████████████████████████████████| 365 kB 39.9 MB/s \n","\u001b[K     |████████████████████████████████| 251 kB 45.1 MB/s \n","\u001b[K     |████████████████████████████████| 191 kB 54.7 MB/s \n","\u001b[K     |████████████████████████████████| 178 kB 54.3 MB/s \n","\u001b[?25h  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SYcwkPBS30cM","executionInfo":{"status":"ok","timestamp":1627184377778,"user_tz":-420,"elapsed":12,"user":{"displayName":"Minh Nguyễn Lê","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAYNRGjCirq6Cpw1HL6UX7HEogIFowg0H8D5EI=s64","userId":"13258555114894503374"}}},"source":["EOS = text_encoder.EOS_ID\n","\n","_ENVI_TRAIN_SMALL_DATA = [\n","    [\n","        \"https://github.com/WilliamDunbar/Machine_Translation/blob/master/Data.rar\",\n","        (\"dev.en\",\n","         \"dev.vi\")\n","    ],\n","]\n","_ENVI_TEST_SMALL_DATA = [\n","    [\n","        \"https://github.com/WilliamDunbar/Machine_Translation/blob/master/Data.rar\",\n","        (\"test.en\",\n","         \"test.vi\")\n","    ],\n","]\n","_ENVI_TRAIN_LARGE_DATA = [\n","    [\n","        \"https://github.com/WilliamDunbar/Machine_Translation/blob/master/Data.rar\",\n","        (\"train.en\", \"train.vi\")\n","    ],\n","]\n","_ENVI_TEST_LARGE_DATA = [\n","    [\n","        \"https://github.com/WilliamDunbar/Machine_Translation/blob/master/Data.rar\",\n","        (\"test.en\", \"test.vi\")\n","    ],\n","]\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"ApYQyBp8-emG","executionInfo":{"status":"ok","timestamp":1627184377779,"user_tz":-420,"elapsed":5,"user":{"displayName":"Minh Nguyễn Lê","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAYNRGjCirq6Cpw1HL6UX7HEogIFowg0H8D5EI=s64","userId":"13258555114894503374"}}},"source":["@registry.register_problem\n","class TranslateEnViWmtSmall8k(translate.TranslateProblem):\n","  \"\"\"Problem spec for WMT En-Vi translation.\"\"\"\n","\n","  @property\n","  def approx_vocab_size(self):\n","    return 2**13  # 8192\n","\n","  @property\n","  def use_small_dataset(self):\n","    return True\n","\n","  def source_data_files(self, dataset_split):\n","    train = dataset_split == problem.DatasetSplit.TRAIN\n","    if self.use_small_dataset:\n","      datasets = _ENVI_TRAIN_SMALL_DATA if train else _ENVI_TEST_SMALL_DATA\n","    else:\n","      datasets = _ENVI_TRAIN_LARGE_DATA if train else _ENVi_TEST_LARGE_DATA\n","    return datasets\n","\n","  def vocab_data_files(self):\n","    return (_ENVI_TRAIN_SMALL_DATA if self.use_small_dataset\n","            else _ENVI_TRAIN_LARGE_DATA)\n","\n","\n","@registry.register_problem\n","class TranslateEnViWmtSmall32k(TranslateEnViWmtSmall8k):\n","\n","  @property\n","  def approx_vocab_size(self):\n","    return 2**15  # 32768\n","\n","\n","@registry.register_problem\n","class TranslateEnViWmt8k(TranslateEnViWmtSmall8k):\n","\n","  @property\n","  def use_small_dataset(self):\n","    return False\n","\n","\n","@registry.register_problem\n","class TranslateEnViWmt32k(TranslateEnViWmtSmall32k):\n","\n","  @property\n","  def use_small_dataset(self):\n","    return False\n","\n","\n","@registry.register_problem\n","class TranslateEnViWmt32kPacked(TranslateEnViWmt32k):\n","\n","  @property\n","  def packed_length(self):\n","    return 256\n","\n","  @property\n","  def use_vocab_from_other_problem(self):\n","    return TranslateEnViWmt32k()\n","\n","\n","@registry.register_problem\n","class TranslateEnViWmt32kWithBacktranslateVi(TranslateEnViWmt32k):\n","  \"\"\"En-Vi translation with added VietNam data, back-translated.\"\"\"\n","\n","  @property\n","  def use_vocab_from_other_problem(self):\n","    return TranslateEnViWmt32k()\n","\n","  @property\n","  def already_shuffled(self):\n","    return True\n","\n","  @property\n","  def skip_random_fraction_when_training(self):\n","    return False\n","\n","  @property\n","  def backtranslate_data_filenames(self):\n","    \"\"\"List of pairs of files with matched back-translated data.\"\"\"\n","    # Files must be placed in tmp_dir, each similar size to authentic data.\n","    return [(\"en_mono_en.txt\", \"en_mono_vi.txt\")]\n","\n","  @property\n","  def dataset_splits(self):\n","    \"\"\"Splits of data to produce and number of output shards for each.\"\"\"\n","    return [{\n","        \"split\": problem.DatasetSplit.TRAIN,\n","        \"shards\": 1,  # Use just 1 shard so as to not mix data.\n","    }, {\n","        \"split\": problem.DatasetSplit.EVAL,\n","        \"shards\": 1,\n","    }]\n","\n","  def generate_samples(self, data_dir, tmp_dir, dataset_split):\n","    datasets = self.source_data_files(dataset_split)\n","    tag = \"train\" if dataset_split == problem.DatasetSplit.TRAIN else \"dev\"\n","    data_path = translate.compile_data(\n","        tmp_dir, datasets, \"%s-compiled-%s\" % (self.name, tag))\n","    # For eval, use authentic data.\n","    if dataset_split != problem.DatasetSplit.TRAIN:\n","      for example in text_problems.text2text_txt_iterator(\n","          data_path + \".lang1\", data_path + \".lang2\"):\n","        yield example\n","    else:  # For training, mix synthetic and authentic data as follows.\n","      for (file1, file2) in self.backtranslate_data_filenames:\n","        path1 = os.path.join(tmp_dir, file1)\n","        path2 = os.path.join(tmp_dir, file2)\n","        # Synthetic data first.\n","        for example in text_problems.text2text_txt_iterator(path1, path2):\n","          yield example\n","        # Now authentic data.\n","        for example in text_problems.text2text_txt_iterator(\n","            data_path + \".lang1\", data_path + \".lang2\"):\n","          yield example\n","\n","\n","@registry.register_problem\n","class TranslateEnViWmt32kWithBacktranslateEn(\n","    TranslateEnViWmt32kWithBacktranslateVi):\n","  \"\"\"En-Vi translation with added English data, back-translated.\"\"\"\n","\n","  @property\n","  def backtranslate_data_filenames(self):\n","    \"\"\"List of pairs of files with matched back-translated data.\"\"\"\n","    # Files must be placed in tmp_dir, each similar size to authentic data.\n","    return [(\"en_mono_en.txt%d\" % i, \"en_mono_vi.txt%d\" % i) for i in [0, 1, 2]]\n","\n","\n","@registry.register_problem\n","class TranslateEnViWmtSmallCharacters(translate.TranslateProblem):\n","  \"\"\"Problem spec for WMT En-Vi translation.\"\"\"\n","\n","  @property\n","  def vocab_type(self):\n","    return text_problems.VocabType.CHARACTER\n","\n","  @property\n","  def use_small_dataset(self):\n","    return True\n","\n","  def source_data_files(self, dataset_split):\n","    train = dataset_split == problem.DatasetSplit.TRAIN\n","    if self.use_small_dataset:\n","      datasets = _ENVI_TRAIN_SMALL_DATA if train else _ENVI_TEST_SMALL_DATA\n","    else:\n","      datasets = _ENVI_TRAIN_LARGE_DATA if train else _ENVI_TEST_LARGE_DATA\n","    return datasets\n","\n","\n","@registry.register_problem\n","class TranslateEnViWmtCharacters(TranslateEnViWmtSmallCharacters):\n","\n","  @property\n","  def use_small_dataset(self):\n","    return False\n","\n","\n","@registry.register_problem\n","class TranslateEnViWmtMulti64k(TranslateEnViWmtSmall32k):\n","  \"\"\"Translation with muli-lingual vocabulary.\"\"\"\n","\n","  @property\n","  def use_small_dataset(self):\n","    return False\n","\n","  @property\n","  def use_vocab_from_other_problem(self):\n","    return wiki_lm.LanguagemodelDeEnViRoWiki64k()\n","\n","\n","@registry.register_problem\n","class TranslateEnViWmtMulti64kPacked1k(TranslateEnViWmtMulti64k):\n","  \"\"\"Translation with muli-lingual vocabulary.\"\"\"\n","\n","  @property\n","  def packed_length(self):\n","    return 1024\n","\n","  @property\n","  def num_training_examples(self):\n","    return 1760600\n","\n","  @property\n","  def inputs_prefix(self):\n","    return \"translate English VietNam \"\n","\n","  @property\n","  def targets_prefix(self):\n","    return \"translate VietNam English \""],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"5qbG1FZS_vzX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627184564518,"user_tz":-420,"elapsed":4491,"user":{"displayName":"Minh Nguyễn Lê","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAYNRGjCirq6Cpw1HL6UX7HEogIFowg0H8D5EI=s64","userId":"13258555114894503374"}},"outputId":"0f0ec5c4-849e-4d56-8744-c91f26fd74a7"},"source":["!pip install kora\n","from kora import console\n","console.start()  # and click link"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting kora\n","  Downloading kora-0.9.19-py3-none-any.whl (57 kB)\n","\u001b[K     |████████████████████████████████| 57 kB 3.2 MB/s \n","\u001b[?25hCollecting fastcore\n","  Downloading fastcore-1.3.20-py3-none-any.whl (53 kB)\n","\u001b[K     |████████████████████████████████| 53 kB 2.1 MB/s \n","\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from kora) (5.5.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.0)\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.1.3)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (5.0.5)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (57.2.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.7.5)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (1.0.18)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (2.6.1)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.8.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (0.2.5)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->kora) (0.2.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastcore->kora) (2.4.7)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->kora) (0.7.0)\n","Installing collected packages: fastcore, kora\n","Successfully installed fastcore-1.3.20 kora-0.9.19\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"us58tz8JwU1n","executionInfo":{"status":"ok","timestamp":1627189581912,"user_tz":-420,"elapsed":4998789,"user":{"displayName":"Minh Nguyễn Lê","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAYNRGjCirq6Cpw1HL6UX7HEogIFowg0H8D5EI=s64","userId":"13258555114894503374"}},"outputId":"c4028ca1-52c0-48e7-8d2c-0da1d115ccc2"},"source":["!bash"],"execution_count":7,"outputs":[{"output_type":"stream","text":["bash: cannot set terminal process group (61): Inappropriate ioctl for device\n","bash: no job control in this shell\n","\u001b[1;36m/content\u001b[m# \n","\u001b[1;36m/content\u001b[m# \n","\u001b[1;36m/content\u001b[m# exit\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x9shbBGkwlAF"},"source":[""],"execution_count":null,"outputs":[]}]}